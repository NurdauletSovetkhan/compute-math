# Curve Fitting: Пояснение к программе

## Содержание
1. [Метод наименьших квадратов](#метод-наименьших-квадратов)
2. [Модели аппроксимации](#модели-аппроксимации)
   - [Прямая линия](#1-прямая-линия-straight-line)
   - [Квадратичная функция](#2-квадратичная-функция-quadratic)
   - [Кубическая функция](#3-кубическая-функция-cubic)
   - [Экспоненциальная функция](#4-экспоненциальная-функция-exponential)
   - [Логарифмическая функция](#5-логарифмическая-функция-logarithmic)
   - [Степенная функция](#6-степенная-функция-power)
3. [Структура программы](#структура-программы)
4. [SSE — Sum of Squared Errors](#sse--sum-of-squared-errors)

---

## Метод наименьших квадратов

**Метод наименьших квадратов (МНК)** — математический метод для нахождения наилучшего приближения к набору данных.

### Идея метода

Дано: набор точек $(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)$

Цель: найти такие коэффициенты модели, чтобы **сумма квадратов отклонений** была минимальной:

$$SSE = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \to \min$$

где $\hat{y}_i$ — предсказанное значение по модели.

### Почему квадраты?

1. **Устранение знака** — положительные и отрицательные ошибки не компенсируют друг друга
2. **Штраф за большие ошибки** — большие отклонения "наказываются" сильнее
3. **Дифференцируемость** — функция гладкая, легко найти минимум

### Нормальные уравнения

Для минимизации SSE берём частные производные по коэффициентам и приравниваем к нулю. Это даёт систему **нормальных уравнений**, решение которой — оптимальные коэффициенты.

---

## Модели аппроксимации

### 1. Прямая линия (Straight Line)

**Модель:** $y = ax + b$

**Нормальные уравнения:**

$$\begin{cases}
a \cdot \sum x_i^2 + b \cdot \sum x_i = \sum x_i y_i \\
a \cdot \sum x_i + b \cdot n = \sum y_i
\end{cases}$$

**Матричная форма:**

$$\begin{pmatrix} \sum x^2 & \sum x \\ \sum x & n \end{pmatrix} \begin{pmatrix} a \\ b \end{pmatrix} = \begin{pmatrix} \sum xy \\ \sum y \end{pmatrix}$$

**Решение:** Используем правило Крамера для системы 2×2.

**Файл:** `methods/straight_line.py`

---

### 2. Квадратичная функция (Quadratic)

**Модель:** $y = ax^2 + bx + c$

**Нормальные уравнения (система 3×3):**

$$\begin{pmatrix} 
\sum x^4 & \sum x^3 & \sum x^2 \\ 
\sum x^3 & \sum x^2 & \sum x \\ 
\sum x^2 & \sum x & n 
\end{pmatrix} 
\begin{pmatrix} a \\ b \\ c \end{pmatrix} = 
\begin{pmatrix} \sum x^2 y \\ \sum xy \\ \sum y \end{pmatrix}$$

**Решение:** Метод Гаусса для системы 3×3.

**Файл:** `methods/quadratic.py`

---

### 3. Кубическая функция (Cubic)

**Модель:** $y = ax^3 + bx^2 + cx + d$

**Нормальные уравнения (система 4×4):**

$$\begin{pmatrix} 
\sum x^6 & \sum x^5 & \sum x^4 & \sum x^3 \\ 
\sum x^5 & \sum x^4 & \sum x^3 & \sum x^2 \\ 
\sum x^4 & \sum x^3 & \sum x^2 & \sum x \\
\sum x^3 & \sum x^2 & \sum x & n
\end{pmatrix} 
\begin{pmatrix} a \\ b \\ c \\ d \end{pmatrix} = 
\begin{pmatrix} \sum x^3 y \\ \sum x^2 y \\ \sum xy \\ \sum y \end{pmatrix}$$

**Решение:** Метод Гаусса для системы 4×4.

**Файл:** `methods/cubic.py`

---

### 4. Экспоненциальная функция (Exponential)

**Модель:** $y = a \cdot e^{bx}$

**Проблема:** Модель нелинейна по коэффициентам — МНК напрямую не применим.

**Решение — Линеаризация:**

Берём логарифм обеих сторон:
$$\ln y = \ln a + bx$$

Вводим замену: $Y = \ln y$, $A = \ln a$

Получаем линейную модель: $Y = A + bx$

**После решения:**
- $b$ — находим напрямую
- $a = e^A$

**Ограничение:** Все значения $y$ должны быть положительными.

**Файл:** `methods/exponential.py`

---

### 5. Логарифмическая функция (Logarithmic)

**Модель:** $y = a + b \cdot \ln x$

**Особенность:** Модель уже линейна по $\ln x$!

**Замена:** $X = \ln x$

**Линейная форма:** $y = a + bX$

**Нормальные уравнения:**

$$\begin{pmatrix} n & \sum \ln x \\ \sum \ln x & \sum (\ln x)^2 \end{pmatrix} \begin{pmatrix} a \\ b \end{pmatrix} = \begin{pmatrix} \sum y \\ \sum y \cdot \ln x \end{pmatrix}$$

**Ограничение:** Все значения $x$ должны быть положительными.

**Файл:** `methods/logarithmic.py`

---

### 6. Степенная функция (Power)

**Модель:** $y = a \cdot x^b$

**Линеаризация:**

$$\ln y = \ln a + b \cdot \ln x$$

**Замены:** $Y = \ln y$, $X = \ln x$, $A = \ln a$

**Линейная форма:** $Y = A + bX$

**После решения:**
- $b$ — находим напрямую
- $a = e^A$

**Ограничение:** Все значения $x$ и $y$ должны быть положительными.

**Файл:** `methods/power.py`

---

## Структура программы

```
assignment-3/
├── main.py              # CLI меню, запуск программы
├── utils.py             # Вспомогательные функции
├── table.py             # Вывод таблиц результатов
├── graph.py             # Визуализация графиков
├── examples.py          # Готовые примеры данных
├── README.md            # Описание задания
├── explain.md           # Это пояснение
└── methods/
    ├── __init__.py      # Экспорт всех моделей
    ├── straight_line.py # y = ax + b
    ├── quadratic.py     # y = ax² + bx + c
    ├── cubic.py         # y = ax³ + bx² + cx + d
    ├── exponential.py   # y = a·e^(bx)
    ├── logarithmic.py   # y = a + b·ln(x)
    └── power.py         # y = a·x^b
```

### Описание модулей

| Модуль | Описание |
|--------|----------|
| `main.py` | Главный файл. CLI меню для выбора примеров или ввода своих данных. Поддерживает выбор конкретных моделей. |
| `utils.py` | Функция `calculate_sse()` для подсчёта SSE. Функции `solve_2x2()`, `solve_3x3()`, `solve_4x4()` для решения систем линейных уравнений методом Гаусса. |
| `table.py` | Форматированный вывод таблиц с использованием библиотеки `tabulate`. |
| `graph.py` | Построение графиков с помощью `matplotlib`. Отображает все модели на одном графике. |
| `examples.py` | Три готовых набора данных для демонстрации (линейный, экспоненциальный, логарифмический). |

---

## SSE — Sum of Squared Errors

**SSE (Sum of Squared Errors)** — сумма квадратов ошибок.

$$SSE = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$

где:
- $y_i$ — фактическое значение
- $\hat{y}_i$ — предсказанное значение модели

### Интерпретация

| SSE | Значение |
|-----|----------|
| SSE = 0 | Идеальное совпадение (модель проходит через все точки) |
| SSE малое | Хорошая аппроксимация |
| SSE большое | Плохая аппроксимация |

### Выбор лучшей модели

Программа сравнивает SSE всех моделей и выбирает ту, у которой **SSE минимальный** — это и есть лучшая модель для данного набора данных.

**Важно:** Низкий SSE не всегда означает лучшую модель в общем смысле. Полиномы высокой степени могут "переобучиться" (overfitting) — идеально пройти через все точки, но плохо предсказывать новые данные.

---

## Алгоритм работы программы

1. **Ввод данных** — пользователь вводит значения $x$ и $y$ (или выбирает готовый пример)

2. **Обучение моделей** — для каждой из 6 моделей:
   - Строятся нормальные уравнения
   - Решается система линейных уравнений
   - Находятся оптимальные коэффициенты

3. **Вычисление SSE** — для каждой модели считается сумма квадратов ошибок

4. **Вывод результатов** — таблица с уравнениями и SSE

5. **Определение лучшей модели** — модель с минимальным SSE

6. **Визуализация** — график со всеми моделями и исходными точками

---

## Пример работы

**Входные данные:**
```
x: 1  2  3  4  5
y: 1.2  1.9  3.2  3.9  5.1
```

**Результат:**
```
+-----+------------------------+----------------------------------+--------+
|   # | Model                  | Fitted Equation                  |    SSE |
+=====+========================+==================================+========+
|   1 | Straight Line          | y = 0.9800x + 0.1400             | 0.1080 |
+-----+------------------------+----------------------------------+--------+
|   2 | Quadratic (2nd degree) | y = 0.0143x² + 0.8514x + 0.2286  | 0.0997 |
+-----+------------------------+----------------------------------+--------+
...
```

**Лучшая модель:** та, у которой SSE минимальный.
